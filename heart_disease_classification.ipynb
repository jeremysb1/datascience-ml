{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5Z93V9790i4X8ox8Fcunx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeremysb1/machine-learning/blob/main/heart_disease_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predicting Heart Disease using Machine Learning**\n",
        "\n",
        "This notebook will introduce some machine learning and data science concepts by exploring the problem of heart disease classification.\n",
        "\n",
        "It is intended to be an end-to-end example of a data science and machine learning proof of concept."
      ],
      "metadata": {
        "id": "GjJ8pJk0z2Ek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is classification?**\n",
        "\n",
        "Classification involves deciding whether a sample is part of one class or another (single-class classification). If there are multiple class options, it's referred to as multi-class classification."
      ],
      "metadata": {
        "id": "vr5XtTZQ0Kl1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'll approach the problem with the a machine learning modelling framework."
      ],
      "metadata": {
        "id": "qW48RzTU0VHK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "More specifically, I'll look at the following topics.\n",
        "\n",
        "- Exploratory data analysis (EDA) - the process of going through a dataset and finding out more about it.\n",
        "- Model training - create model(s) to learn to predict a target variable based on other variables.\n",
        "- Model evaluation - evaluating a models predictions using problem-specific evaluation metrics.\n",
        "- Model comparison - comparing several different models to find the best one.\n",
        "- Model fine-tuning - once I've found a good model, how can I improve it?\n",
        "Feature importance - since we're predicting the presence of heart disease, are there some things which are more important for prediction?\n",
        "- Cross-validation - if I do build a good model, can I be sure it will work on unseen data?\n",
        "- Reporting - if I had to present our work, what would I show someone?\n",
        "\n",
        "To work through these topics, I'll use pandas, Matplotlib and NumPy for data anaylsis, and Scikit-Learn for machine learning and modelling tasks."
      ],
      "metadata": {
        "id": "Mn34xcqS0qXA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'll work through each step and by the end of the notebook, I'll have a handful of models, all which can predict whether or not a person has heart disease based on a number of different parameters at a considerable accuracy.\n",
        "\n",
        "I'll also be able to describe which parameters are more indicative than others, for example, sex may be more important than age."
      ],
      "metadata": {
        "id": "J89Zy5IT1iN5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.** **Problem Definition**\n",
        "\n",
        "In this case, the problem I will be exploring is binary classification (a sample can only be one of two things).\n",
        "\n",
        "This is because I'm going to be using a number of differnet features (pieces of information) about a person to predict whether they have heart disease or not.\n",
        "\n",
        "In a statement,\n",
        "\n",
        "Given clinical parameters about a patient, can we predict whether or not they have heart disease?\n",
        "\n"
      ],
      "metadata": {
        "id": "v84Kk18M1ns0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Data**\n",
        "\n",
        "What I want to do here is dive into the data the problem definition is based on. This may involve, sourcing, defining different parameters, talking to experts about it and finding out what you should expect.\n",
        "\n",
        "The original data came from the Cleveland database from UCI Machine Learning Repository.\n",
        "\n",
        "Howevever, I've downloaded it in a formatted way from Kaggle.\n",
        "\n",
        "The original database contains 76 attributes, but here only 14 attributes will be used. Attributes (also called features) are the variables used to predict our target variable.\n",
        "\n",
        "Attributes and features are also referred to as independent variables and a target variable can be referred to as a dependent variable.\n",
        "\n",
        "I use the independent variables to predict a dependent variable.\n",
        "\n",
        "Or in this case, the independent variables are a patients different medical attributes and the dependent variable is whether or not they have heart disease."
      ],
      "metadata": {
        "id": "EYCdvYi50ZQl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Evaluation**\n",
        "\n",
        "The evaluation metric is something you might define at the start of a project.\n",
        "\n",
        "Since machine learning is very experimental, you might say something like,\n",
        "\n",
        "If we can reach 95% accuracy at predicting whether or not a patient has heart disease during the proof of concept, we'll pursure this project.\n",
        "\n",
        "The reason this is helpful is it provides a rough goal for a machine learning engineer or data scientist to work towards.\n",
        "\n",
        "However, due to the nature of experimentation, the evaluation metric may change over time.\n",
        "\n"
      ],
      "metadata": {
        "id": "ImUX5grC2fr4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Features**\n",
        "\n",
        "Features are different parts of the data. During this step, I am finding out what I can about the data.\n",
        "\n",
        "One of the most common ways to do this, is to create a data dictionary."
      ],
      "metadata": {
        "id": "ZyAoE4-N2puc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Heart Disease Data Dictionary**\n",
        "\n",
        "A data dictionary describes the data you're dealing with. Not all datasets come with them so this is where you may have to do your research or ask a subject matter expert (someone who knows about the data) for more.\n",
        "\n",
        "The following are the features I'll use to predict our target variable (heart disease or no heart disease).\n",
        "\n",
        "1. age - age in years\n",
        "2. sex - (1 = male; 0 = female)\n",
        "3. cp - chest pain type\n",
        "  - 0: Typical angina: chest pain related decrease blood supply to the heart\n",
        "  - 1: Atypical angina: chest pain not related to heart\n",
        "  - 2: Non-anginal pain: typically esophageal spasms (non heart related)\n",
        "  - 3: Asymptomatic: chest pain not showing signs of disease\n",
        "4. trestbps - resting blood pressure (in mm Hg on admission to the hospital)\n",
        "anything above 130-140 is typically cause for concern\n",
        "5. chol - serum cholestoral in mg/dl\n",
        "  - serum = LDL + HDL + .2 * triglycerides\n",
        "  - above 200 is cause for concern\n",
        "6. fbs - (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n",
        "'>126' mg/dL signals diabetes\n",
        "7. restecg - resting electrocardiographic results\n",
        "  - 0: Nothing to note\n",
        "  - 1: ST-T Wave abnormality\n",
        "      - can range from mild symptoms to severe problems\n",
        "      - signals non-normal heart beat\n",
        "  - 2: Possible or definite left ventricular hypertrophy\n",
        "      - Enlarged heart's main pumping chamber\n",
        "8. thalach - maximum heart rate achieved\n",
        "9. exang - exercise induced angina (1 = yes; 0 = no)\n",
        "10. oldpeak - ST depression induced by exercise relative to rest\n",
        "  - looks at stress of heart during excercise\n",
        "  - unhealthy heart will stress more\n",
        "11. slope - the slope of the peak exercise ST segment\n",
        "  - 0: Upsloping: better heart rate with excercise (uncommon)\n",
        "  - 1: Flatsloping: minimal change (typical healthy heart)\n",
        "  - 2: Downslopins: signs of unhealthy heart\n",
        "12. ca - number of major vessels (0-3) colored by flourosopy\n",
        "  - colored vessel means the doctor can see the blood passing through\n",
        "  - the more blood movement the better (no clots)\n",
        "13. thal - thalium stress result\n",
        "  - 1,3: normal\n",
        "  - 6: fixed defect: used to be defect but ok now\n",
        "  - 7: reversable defect: no proper blood movement when excercising\n",
        "14. target - have disease or not (1=yes, 0=no) (= the predicted attribute)\n",
        "\n",
        "Note: No personal identifiable information (PPI) can be found in the dataset."
      ],
      "metadata": {
        "id": "5hrAoFPA24H-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing the tools\n",
        "\n",
        "At the start of any project, it's custom to see the required libraries imported in a big chunk like you can see below.\n",
        "\n",
        "However, in practice, projects may import libraries as you go.\n",
        "\n",
        "The libraries you use will differ from project to project. But there are some common ones during almost every structured data project.\n",
        "\n",
        "- pandas for data analysis.\n",
        "- NumPy for numerical operations.\n",
        "- Matplotlib/seaborn for plotting or data visualization.\n",
        "- Scikit-Learn for machine learning modelling and evaluation."
      ],
      "metadata": {
        "id": "IN7_07fg4pI7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_JVEvXsszyHZ"
      },
      "outputs": [],
      "source": [
        "# regular eda and plotting libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# want plots to appear in the notebook\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "NemOmYXA56Vs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# models and model evaluators\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# model evaluators\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import plot_roc_curve"
      ],
      "metadata": {
        "id": "-tbl6BLYMex0"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}